{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid Depricated warnings\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for parsing data from date column as date\n",
    "def parser(x):\n",
    "    return pd.datetime.strptime(x, '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset as Pandas DataFrame\n",
    "dataset = pd.read_csv(\"dataset.csv\", parse_dates=[0], date_parser=parser, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping NA values from Date, Market, Keyword\n",
    "dataset = dataset[pd.isna(dataset[1]) == False]\n",
    "dataset = dataset[pd.isna(dataset[0]) == False]\n",
    "dataset = dataset[pd.isna(dataset[3]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Date column as pandas.DateTime\n",
    "dataset.iloc[:, 0] = pd.to_datetime(dataset.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Day of Week number column into dataset\n",
    "dataset[9] = dataset[0].apply(lambda x: x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Is_Holiday column into dataset for Holiday Date's\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dataset[0].min(), end=dataset[0].max())\n",
    "dataset[10] = dataset[0].isin(holidays)\n",
    "dataset.iloc[:, 10] = dataset.iloc[:, 10].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>US-Market</td>\n",
       "      <td>secure online back up</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>US-Market</td>\n",
       "      <td>agile management software</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>21.22</td>\n",
       "      <td>8.20%</td>\n",
       "      <td>260.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>US-Market</td>\n",
       "      <td>crm for financial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>US-Market</td>\n",
       "      <td>disaster recovery planning for it</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>US-Market</td>\n",
       "      <td>tracking a vehicle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1                                  2    3    4      5   \\\n",
       "0 2012-05-24  US-Market              secure online back up  0.0  0.0   0.00   \n",
       "1 2012-05-24  US-Market          agile management software  1.0  1.2  21.22   \n",
       "2 2012-05-24  US-Market                  crm for financial  0.0  0.0   0.00   \n",
       "3 2012-05-24  US-Market  disaster recovery planning for it  0.0  0.0   0.00   \n",
       "4 2012-05-24  US-Market                 tracking a vehicle  0.0  0.0   0.00   \n",
       "\n",
       "      6      7      8   9   10  \n",
       "0  0.00%    0.0   0.00   3   0  \n",
       "1  8.20%  260.0  25.45   3   0  \n",
       "2  0.00%    0.0   0.00   3   0  \n",
       "3  0.00%    0.0   0.00   3   0  \n",
       "4  0.00%    0.0   0.00   3   0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all keywords into lower case\n",
    "dataset.iloc[:, 2] = dataset.iloc[:, 2].astype(\"str\")\n",
    "dataset[2] = dataset[2].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ghost/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ghost/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing NLTK Libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:, 2] = dataset.iloc[:, 2].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlpo(x):\n",
    "    ww = []\n",
    "    for word in x:\n",
    "        if not word in set(stopwords.words('english')):\n",
    "          ww.append(lemmatizer.lemmatize(ps.stem(word)))\n",
    "    return ww\n",
    "\n",
    "dataset.iloc[:, 2] = dataset.iloc[:, 2].apply(lambda x: nlpo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [secur, onlin, back]\n",
       "1        [agil, manag, softwar]\n",
       "2                [crm, financi]\n",
       "3      [disast, recoveri, plan]\n",
       "4               [track, vehicl]\n",
       "5               [applic, cloud]\n",
       "6       [project, manag, scrum]\n",
       "7                [server, busi]\n",
       "8    [android, applic, develop]\n",
       "9       [android, app, develop]\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the words again as sentence\n",
    "dataset.iloc[:, 2] = dataset.iloc[:, 2].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset\n",
    "X = dataset.iloc[:, [1, 2, 4, 9, 10]].values\n",
    "y = dataset.iloc[:, 5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_market = LabelEncoder()\n",
    "X[:, 0] = labelencoder_market.fit_transform(X[:, 0])\n",
    "\n",
    "labelencoder_keyword = LabelEncoder()\n",
    "X[:, 1] = labelencoder_keyword.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "                      oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RandomForest model to training dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=10, random_state=0, n_jobs=2)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can not apply confution matrix to continuous values\n",
    "# so using cutoff method\n",
    "cutoff = 0.7                              \n",
    "y_pred_classes = np.zeros_like(y_pred)    \n",
    "y_pred_classes[y_pred > cutoff] = 1       \n",
    "\n",
    "y_test_classes = np.zeros_like(y_pred)\n",
    "y_test_classes[y_test > cutoff] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30890  1073]\n",
      " [  137 38504]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9828621607840915"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy with RandomForest Model\n",
    "print(cm)\n",
    "(30890+38504)/(30890+1073+137+38504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as ltb\n",
    "# fit a lightGBM model to the data\n",
    "model = ltb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20198 11765]\n",
      " [ 2108 36533]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_ltb = np.zeros_like(predicted_y)\n",
    "y_pred_ltb[predicted_y > cutoff] = 1\n",
    "y_test_ltb = np.zeros_like(predicted_y)\n",
    "y_test_ltb[y_test > cutoff] = 1\n",
    "cm_ltb = confusion_matrix(y_test_ltb, y_pred_ltb)\n",
    "print(cm_ltb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035097161633902"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20198+36533)/(20198+11765+2108+36533)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
